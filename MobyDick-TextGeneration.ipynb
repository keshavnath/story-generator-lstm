{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-keras-2-lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Writing style mimicry using LSTM\n",
        "using Herman Melville's _Moby Dick_ as reference"
      ],
      "metadata": {
        "id": "ra8e91_rO715"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Data Loading"
      ],
      "metadata": {
        "id": "k7Kjh7jdPJmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0xJFDAe2rRK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filepath):\n",
        "  with open(filepath) as f:\n",
        "    str_text = f.read()\n",
        "  \n",
        "  return str_text"
      ],
      "metadata": {
        "id": "_5bl-nxY4oqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "PpePcso4Pv_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "cPtmMmcE4v1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en\",disable=['parser','tagger','ner'])"
      ],
      "metadata": {
        "id": "RH0MkUod6IjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.max_length = 11198623"
      ],
      "metadata": {
        "id": "HRpGTVzM6PpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seperate_punc(doc_text):\n",
        "  return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_{|}~t\\\\n ']"
      ],
      "metadata": {
        "id": "j-65oc6Z6dOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = read_file('moby_dick_four_chapters.txt')"
      ],
      "metadata": {
        "id": "Iey2KbCJ7Nnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = seperate_punc(d)"
      ],
      "metadata": {
        "id": "Tp9ONz577V6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvGFZQcD7eic",
        "outputId": "55e7cc49-7b41-433d-c7e8-ee6b72049ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence generation (26 word sequences, 25 as X and 26 as Y)"
      ],
      "metadata": {
        "id": "XZhH8n21P2LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 25 words --> network predict #26"
      ],
      "metadata": {
        "id": "Bou2Gzem7mny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = 25 + 1\n",
        "\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len,len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ],
      "metadata": {
        "id": "kw_GFSrQ7t7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "T2Wc-8Cn8I-S",
        "outputId": "a71b823a-c147-4a47-f3cd-ac9555e1a176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Xmc9o5XA8KiC",
        "outputId": "5a83b6b7-2452-4222-a366-9a9e3aa24b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "BxSdGs38P5t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "TLniGJC88WST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text_sequences)"
      ],
      "metadata": {
        "id": "aLu_ZxPq8mcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "metadata": {
        "id": "PUhI2g9083hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences[0]:\n",
        "  print(f\"{i} : {tokenizer.index_word[i]}\")\n",
        "# tokenizer.index_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr6HfbKw867S",
        "outputId": "4f571948-4207-4b4e-dd6c-b9bd0388fc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "956 : call\n",
            "14 : me\n",
            "263 : ishmael\n",
            "51 : some\n",
            "261 : years\n",
            "408 : ago\n",
            "87 : never\n",
            "219 : mind\n",
            "129 : how\n",
            "111 : long\n",
            "954 : precisely\n",
            "260 : having\n",
            "50 : little\n",
            "43 : or\n",
            "38 : no\n",
            "315 : money\n",
            "7 : in\n",
            "23 : my\n",
            "546 : purse\n",
            "3 : and\n",
            "150 : nothing\n",
            "259 : particular\n",
            "6 : to\n",
            "2712 : interest\n",
            "14 : me\n",
            "24 : on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "vocabulary_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpj0OetK88Yb",
        "outputId": "916094ac-abe8-4efd-a1f5-2228556d2e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o25aJ8hi9YWK",
        "outputId": "6ef6bd3c-5e05-4139-e2e6-ae6c34967b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
              "       [  14,  263,   51, ...,   14,   24,  957],\n",
              "       [ 263,   51,  261, ...,   24,  957,    5],\n",
              "       ...,\n",
              "       [ 952,   12,  166, ...,  262,   53,    2],\n",
              "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
              "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opX0_Eqp-ykz",
        "outputId": "96f557b9-dd5e-4249-875b-a90371b14ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11312, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "yS3P6iRO9wna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "O6leQCuM-Njz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y,num_classes=vocabulary_size+1)"
      ],
      "metadata": {
        "id": "oHfDPSVs-Rby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = X.shape[1]"
      ],
      "metadata": {
        "id": "dghUj5Ku-rdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model creation"
      ],
      "metadata": {
        "id": "fm9KFzqpQG_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "Kf1OH5ea-uCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocabulary_size,seq_len):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
        "  model.add(LSTM(seq_len*2,return_sequences=True))\n",
        "  model.add(LSTM(seq_len*2))\n",
        "  model.add(Dense(50,activation='relu'))\n",
        "\n",
        "  model.add(Dense(vocabulary_size,activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q-6zOppf_Bez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocabulary_size+1,seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NelIXZ-M_4pr",
        "outputId": "67794cb0-4039-4063-eea9-44468c12419d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 25)            67950     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 25, 50)            15200     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2718)              138618    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 244,518\n",
            "Trainable params: 244,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump,load"
      ],
      "metadata": {
        "id": "6XZ4f7xeABgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,batch_size=128,epochs=5,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QkoqayrALHa",
        "outputId": "1bf43e49-ff35-4164-ca08-7516a73bb1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "89/89 [==============================] - 5s 55ms/step - loss: 6.3440 - accuracy: 0.0529\n",
            "Epoch 2/5\n",
            "89/89 [==============================] - 5s 55ms/step - loss: 6.3131 - accuracy: 0.0529\n",
            "Epoch 3/5\n",
            "89/89 [==============================] - 5s 54ms/step - loss: 6.1984 - accuracy: 0.0529\n",
            "Epoch 4/5\n",
            "89/89 [==============================] - 5s 54ms/step - loss: 6.1140 - accuracy: 0.0529\n",
            "Epoch 5/5\n",
            "89/89 [==============================] - 6s 63ms/step - loss: 6.0056 - accuracy: 0.0540\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8308c573d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_mobydick_model.h5')"
      ],
      "metadata": {
        "id": "CDQMQA62AeC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump(tokenizer,open('my_simpletokenizer',\"wb\"))"
      ],
      "metadata": {
        "id": "r0Yy_2yJAuoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "d3aRxBL9Bkqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):\n",
        "\n",
        "  output_text = []\n",
        "\n",
        "  input_text = seed_text\n",
        "\n",
        "  for i in range(num_gen_words):\n",
        "    \n",
        "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    pad_encoded = pad_sequences([encoded_text],maxlen=seq_len,truncating='pre')\n",
        "\n",
        "    pred_word_ind = np.argmax(model.predict(pad_encoded,verbose=0), axis=-1)[0]\n",
        "\n",
        "    pred_word = tokenizer.index_word[pred_word_ind]\n",
        "\n",
        "    input_text += ' '+pred_word\n",
        "\n",
        "    output_text.append(pred_word)\n",
        "\n",
        "  pred_words = ' '.join(output_text)\n",
        "\n",
        "  return str(seed_text + ' | ' + pred_words)"
      ],
      "metadata": {
        "id": "6qTaCClbA0F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "random_pick = random.randint(0,len(text_sequences))\n",
        "random_seed_text = text_sequences[random_pick]\n",
        "seed_text = ' '.join(random_seed_text)\n",
        "seed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3hWX-TEbDE6-",
        "outputId": "f1ee0fe7-fe28-4798-bf01-ec002f672689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"a horse collar and suddenly felt a slight scratch throwing aside the counterpane there lay the tomahawk sleeping by the savage 's side as if it\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text,num_gen_words=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "KAUxqjAcC5X1",
        "outputId": "f5947af5-3165-4222-d042-610acf639ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"a horse collar and suddenly felt a slight scratch throwing aside the counterpane there lay the tomahawk sleeping by the savage 's side as if it | the room the room the room the room the room the room the room the room the room the room the room the room the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It performs badly because we didn't train it for enough epochs, so it kept repeating the most common words :/"
      ],
      "metadata": {
        "id": "p7HCih6HDwfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ysFVSAwUQR2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}